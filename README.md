# AskFred-bcknd



Dies ist das Backend des Chatbot-Projekts, entwickelt mit **Node.js**, **Express.js**, **TypeScript** und **BullMQ**.  
Es verarbeitet Nutzeranfragen asynchron Ã¼ber eine Redis-Queue und simuliert die Ãœbergabe an KI-Dienste wie Gemini, ChatGPT und Copilot.

---

## ğŸ“ Projektstruktur

```
backend/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ index.ts
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .env.example
```

---

## ğŸ“„ DateiÃ¼bersicht

| Datei/Ordner       | Beschreibung |
|--------------------|--------------|
| `src/index.ts`     | Hauptserver mit Express, BullMQ-Queue und Worker |
| `package.json`     | ProjektabhÃ¤ngigkeiten und Startskripte |
| `tsconfig.json`    | TypeScript-Konfiguration |
| `.env.example`     | Beispiel fÃ¼r Umgebungsvariablen (z.â€¯B. Redis-URL, Port) |

---

## âš™ï¸ Setup

### 1. AbhÃ¤ngigkeiten installieren

```bash
npm install
```

### 2. TypeScript kompilieren

```bash
npm run build
```

### 3. Server starten

```bash
npm start
```

---

## ğŸŒ API-Endpunkt

### `POST /api/sessions/start`

Startet eine neue Session und fÃ¼gt sie zur Queue hinzu.

**Body:**

```json
{
  "input": "Deine Anfrage"
}
```

**Response:**

```json
{
  "message": "Session started",
  "jobId": "abc123"
}
```

---

## ğŸ”§ Umgebungsvariablen

Erstelle eine `.env`-Datei basierend auf `.env.example`:

```env
REDIS_URL=redis://localhost:6379
PORT=3000
```

---

## ğŸ§  Verarbeitung

- Die Jobs werden in der Queue `myQueue` gespeichert.
- Ein Worker verarbeitet die Jobs sequentiell.
- Die Verarbeitung simuliert KI-Schritte (Gemini â†’ ChatGPT â†’ Copilot).

---

```

Du kannst diesen Text direkt in deine `README.md` einfÃ¼gen.  
MÃ¶chtest du jetzt mit dem lokalen Test oder dem Deployment fortfahren?
